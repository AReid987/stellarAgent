from notdiamond import NotDiamond

from apps.ai_gateway.src.not_diamond.not_diamond_client import NotDiamondClient
client = NotDiamond()

llm_providers = [
    "cognitivecomputations/dolphin3.0-r1-mistral-24b:free",
    "cognitivecomputations/dolphin3.0-mistral-24b:free",
    "google/gemini-2.0-flash-lite-preview-02-05:free",
    "google/gemini-2.0-flash-lite-preview-02-05:free",
    "google/gemini-2.0-pro-exp-02-05:free",
    "qwen/qwen-vl-plus:free",
    "qwen/qwen2.5-vl-72b-instruct:free",
    "mistralai/mistral-small-24b-instruct-2501:free",
    "deepseek/deepseek-r1-distill-llama-70b:free",
    "google/gemini-2.0-flash-thinking-exp:free",
    "deepseek/deepseek-r1:free",
    "sophosympatheia/rogue-rose-103b-v0.2:free",
    "deepseek/deepseek-chat:free",
    "google/gemini-2.0-flash-thinking-exp-1219:free",
    "google/gemini-2.0-flash-exp:free",
    "google/gemini-exp-1206:free",
    "meta-llama/llama-3.3-70b-instruct:free",
    "google/learnlm-1.5-pro-experimental:free"
    "nvidia/llama-3.1-nemotron-70b-instruct:free",
    "meta-llama/llama-3.2-11b-vision-instruct:free",
    "google/gemini-flash-1.5-8b-exp",
    "google/gemini-flash-1.5-8b-exp",
    "mistralai/mistral-nemo:free",
    "google/gemma-2-9b-it:free",
    "mistralai/mistral-7b-instruct:free",
    "microsoft/phi-3-mini-128k-instruct:free",
    "microsoft/phi-3-medium-128k-instruct:free",
    "meta-llama/llama-3-8b-instruct:free",
    "openchat/openchat-7b:free",
    "undi95/toppy-m-7b:free",
    "huggingfaceh4/zephyr-7b-beta:free",
    "gryphe/mythomax-l2-13b:free",
    "models/gemini-2.0-flash",
    "models/gemini-2.0-flash-lite-preview-02-05",
    "models/gemini-1.5-flash",
    "models/gemini-1.5-flash-8b",
    "models/gemini-1.5-pro",
    "gemini-2.0-pro-exp-02-05",
    "gemini-2.0-flash-thinking-exp-01-21",
    "learnlm-1.5-pro-experimental",
    "mistral/open-mistral-7b",
    "mistral/open-mixtral-8x7b",
    "mistral/open-mixtral-8x22b",
    "mistral/mistral-small-2402",
    "mistral/mistral-small-2409",
    "mistral/mistral-small-2501",
    "mistral/mistral-medium",
    "mistral/mistral-large-2402",
    "mistral/mistral-large-2407",
    "mistral/mistral-large-2411",
    "mistral/mistral-large-2411",
    "mistral/mistral-embed",
    "mistral/mistral-embed",
    "mistral/codestral-2405",
    "mistral/codestral-2501",
    "mistral/codestral-mamba-2407",
    "mistral/open-mistral-nemo",
    "mistral/pixtral-12b-2409",
    "mistral/pixtral-large-2411",
    "mistral/ministral-3b-2410",
    "mistral/ministral-8b-2410",
    "mistral/ministral-8b-2410",
    "mistral/mistral-moderation-2411",
    "cerebras/llama3.1/llama3.1-8b",
    "cerebras/llama3.3/llama3.3-70b",
    "groq/distil-whisper-large-v3-en",
    "groq/gemma2-9b-it",
    "groq/llama-3.3-70b-versatile",
    "groq/lama-3.1-8b-instant",
    "groq/llama-guard-3-8b",
    "groq/llama3-70b-8192",
    "groq/llama3-8b-8192",
    "groq/mixtral-8x7b-32768",
    "groq/whisper-large-v3",
    "groq/whisper-large-v3-turbo",
    "groq/qwen-2.5-32b",
    "groq/deepseek-r1-distill-qwen-32b",
    "groq/deepseek-r1-distill-llama-70b-specdec",
    "groq/deepseek-r1-distill-llama-70b",
    "groq/llama-3.3-70b-specdec",
    "groq/llama-3.2-1b-preview",
    "groq/llama-3.2-3b-preview",
    "groq/llama-3.2-11b-vision-preview",
    "groq/llama-3.2-90b-vision-preview",
    "together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo-Free",
    "together_ai/black-forest-labs/FLUX.1-schnell-Free",
    "together_ai/meta-llama/Llama-Vision-Free",
]

def main():
    not_diamond_client = NotDiamondClient()
    messages = [{"role": "user", "content": "Write a python function to calculate the factorial of a number."}]
    selected_model = not_diamond_client.select_model(messages=messages)
    print(f"Selected model: {selected_model}")

if __name__ == "__main__":
    main()
